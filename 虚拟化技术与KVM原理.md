# 虚拟化技术与KVM原理

## 虚拟化基础原理

### x86内存架构

主要以32位架构为例分析，最后添加x86-64架构下的内容。

**1.地址空间**

​	地址空间划分为物理地址空间和线性地址空间。

1. 物理地址空间

   物理地址空间的大小由CPU实现的物理地址位数决定。由CPU经过MMU转换后的外地址总线位数决定。外线地址总线位数与CPU处理数据的能力没有必然联系，16位的8086CPU有20位地址空间。

   为了让多个程序有效相互隔离，能有效使用物理地址空间的资源，引入线性地址空间。

2. 线性地址空间

   大小由CPU实现的线性地址位数决定，线性地址位数由CPU的内地址总线位数决定。内地址总线位数与CPU一致。如果是32位处理器，其线性地址空间为4GB。

   线性地址空间会被映射到某一部分物理地址空间或整个物理地址空间。在现代操作系统中，每个进程都拥有自己的私有线性地址空间。一个典型的线性地址空间构造：

    ![1578570978](resources\1578570978.jpg)

**2.地址**

地址是访问地址空间的索引。索引可以分为物理地址和线性地址。由于x86特殊的段机制，还有额外一种逻辑地址。

1. 逻辑地址

   是程序直接使用的地址。由一个16位的段选择符和一个32位的偏移量构成。

2. 线性地址

   线性地址又称虚拟地址。是逻辑地址转换后的结果，用于索引线性地址空间。当CPU使用分页机制时，还需要将线性地址转换成物理地址才能访问平台内存或其他物理设备。当分页机制未启用时，线性地址与物理地址相同。

3. 物理地址

   是物理地址空间的索引，是CPU提交到总线用于访问平台内存或其他硬件设备的最终地址。

物理地址与逻辑地址、线性地址的关系

- 分段机制启用，分页机制未启用：逻辑地址 - > 线性地址 = 物理地址
- 分段机制、分页机制同时启用：逻辑地址 - > 线性地址 - > 物理地址

**3.x86内存管理机制**

x86架构的内存管理机制分为两部分：分段机制和分页机制。

​	分段机制为程序提供彼此隔离的代码区域、数据区域、栈区域，从而避免同一处理器上运行多个程序互相影响。

​	分页机制实现传统的按需分页、虚拟内存机制。可以将程序的执行环境按需映射到物理内存。此外，分页机制还可以用于提供多任务的隔离。

1. 分段机制

   分段机制将内存分成以起始地址(Base)和长度(Limit)描述的块。段可以与程序最基本的元素联系起来，程序可以简单划分为代码段、数据段和栈，段机制就有相应的代码段、数据段和栈段。
   分段机制由逻辑地址、段选择符、段描述符和段描述符表4个基本部分结构。当程序使用逻辑地址访问内存时，CPU通过逻辑地址中的段选择符索引段描述符表，进而得到该内存对应的段描述符(段的基地址、长度和读/写、访问权限等信息)。根据属性信息检测访问是否合法。如果合法，再根据基地址将逻辑地址转换为线性地址。

   流程：

    ![1578571998(1)](resources\1578571998(1).jpg)

2. 段选择符

   段选择符是逻辑地址用于索引段描述符表，获取该段对应的段描述符。

    ![1578572066(1)](resources\1578572066(1).jpg)

   各字段含义：

   - 索引(Index)：段描述符表的索引；
   - TI：指明索引哪个段描述符表。TI = 0，表示索引全局段描述符表(GDT)；TI = 1，表示索引本地端描述符表(LDT)；
   - RPL：所要求的权限级别。存在于段选择器的0、1位，为程序访问增加一级检查。

   x86架构提供6个段寄存器存放当前各个段的段选择符。

   - CS(代码段)：存放代码段的段选择符；
   - DS(数据段)：存放数据段的段选择符；
   - SS(栈段)：存放栈的段选择符；
   - ES、FS、GS：存放额外三个数据段的段选择符，由程序自由使用。

   段寄存器的构造

   | 段寄存器名 | 段寄存器 |      程序不可见的段描述符寄存器       |
   | :---: | :--: | :----------------------: |
   |  CS   | 段选择器 | 段的基地址、长度、各种属性(读写属性、访问属性) |

3. 段描述符

    ![1578572566(1)](resources\1578572566(1).jpg)

   - Base字段描述该段的基地址；
   - Limit字段描述该段的长度；
   - DPL字段指明描述符权限级别，表示该段所具有的权限。

4. 段描述符表

   x86提供两种段描述符表：GDT和LDT

   - GDT是内存中的一个数据结构。可以将GDT看成一个数组，由基地址和长度描述。
   - LDT是一个短，需要用一个短描述符来描述。LDT的段描述符存放在GDT中。

   为了加速对GDT和LDT的访问，x86提供GDTR寄存器和LDTR寄存器。

   通过段选择符表索引GDT/LDT的过程

    ![1578573758(1)](resources\1578573758(1).jpg)

5. 逻辑地址转化线性地址

   在程序加载阶段，该进程LDT的段选择符表索引GDT，获得LDT的段描述符并将其加载到LDTR寄存器中。此外，该进程的CS、DS、SS被加载入相应的段选择符。CPU根据段选择符的TI字段索引相应的段描述符表，获得相应的段描述符，并加载入CS、DS、SS对应的不可见段描述符寄存器。

   1. 进行必要的属性、访问权限检查
   2. 从DS对应的段描述符寄存器获得该段的基地址
   3. 将变量的32位偏移量和段描述符中的基地址相加，获得该变量的线性地址

6. 分页机制

   在x86架构下，页的典型大小为4KB，一个4GB的虚拟地址空间被划分为1024 x 1024个页面。x86允许大于4KB的页面大小(2MB、4MB)。

   分页机制的核心是通过页表将线性地址转换为物理地址，并配合旁路转换缓冲区(TLB)加速地址转换的过程。分页机制主要由页表、CR3寄存器和TLB三个部件构成。

    ![1578574795(1)](resources\1578574795(1).jpg)

   1. 页表

      是用于将线性地址转换为物理地址的主要数据结构。一个地址对齐到页边界后的值称为页帧号。线性地址对应虚拟页帧号(VFN)，物理地址对应物理页帧号(PFN)。

      在保护模式下，x86使用两级转换方案，CR3指向一个4KB的页目录，页目录又分为1024个4KB大小的页表。最后页表分为1024个长为4KB的页。

      未启用PAE的4KB的页面

       ![1578575370(1)](resources\1578575370(1).jpg)

      - 页目录项(PDE)：包含页表的物理地址
      - 页表项(PTE)：包含该线性地址对应的PFN。

   2. CR3寄存器

      CR3称为页目录基地址寄存器(PDBR)，存放页目录的物理地址。一个进程在运行前，必须将其页目录的基地址存入CR3，而且，页目录的基地址必须对其到4KB页边界。

      启用PAE时，CR3指向页目录指针表。

       ![1578641143(1)](resources\1578641143(1).jpg)

   3. TLB

      为了提高地址转换的效率，x86架构使用TLB对最近用到的页面映射进行缓存。TLB中存放着VFN到PFN的转换，当CPU访问某个线性地址时，如果其所子啊页面的映射存在于TLB中，无须查找页表，即可得到该线性地址对应的PFN，CPU再将它与线性地址的偏移相加，得到最后的物理地址。

   4. 分页机制总结

      将分页机制的三个部件：页表、CR3寄存器和TLB。这里对CPU使用分页机制将线性地址转换成物理地址的过程进行总结：

      a. CPU访问一个线性地址，在TLB中进行匹配，如果地址转换在TLB中，则跳到步骤f。否则，发生一次TLB Miss(TLB缺失)，则继续步骤b；

      b. 查找页表，如果页面在物理内存中，则跳到步骤d；

      c. 产生缺页错误，由操作系统的缺页错误处理程序进行以下处理：

      - 将页面从磁盘复制到物理内存中；
      - 更改对应的PTE，设置P位为1，并对其他字段进行相应的设置；
      - 刷新TLB中对应的PTE；
      - 从缺页错误处理程序中返回；

      d. 此时，页面已经存在物理内存中，并且页表也已经包含这个映射。重新在TLB中进行匹配，如果地址转换在TLB中，则跳到步骤f。否则，发生一次TLB Miss，继续步骤e；

      e. CPU重新查页表，把对应的映射插入到TLB中；

      f. 此时，TLB已经包含该线性地址对应的PFN。将PFN和线性地址中的偏移量相加，得到对应的物理地址；

7. IA-32e分页机制

   64位寻址模式，PAE是必需的，内存页大小可以是4KB，2MB，1GB。长模式下，附加一个第四季页面映射表。这种机制将48位的线性地址转换为52位物理地址。

    ![1578642572(1)](resources\1578642572(1).jpg)

   四级页表的结构：

   - 第四级页表映射表：包含页目录指针表的物理基地址、访问权限和内存管理信息；PML4的物理基地址存在CR3中；
   - 页目录指针：包含一个页目录表的物理基地址、访问权限和内存管理信息；
   - 页目录项：包含一个页表的物理基地址、访问权限和内存管理信息；
   - 页表项：包含一个页面的物理地址、访问权限和内存管理信息；

### x86 - 64 的基本模式

​	传统的IA -32模式下，x86有三种运行模式：实模式，保护模式和虚拟8086模式。

- 实模式：是Intel 8086处理器工作的模式。该模式下，逻辑地址转换后就是物理地址，操作系统或BIOS通常在该模式下准备必要的数据结构和初始化关键的寄存器，然后切换入保护模式；
- 保护模式：操作系统运行时最常用的模式。在该模式下，CPU的所有功能几乎都能得到使用，可以访问架构允许的所有物理地址空间；
- 虚拟8086模式：该模式让CPU在保护模式下为8086程序虚拟实模式的运行环境，使用这些程序在执行时无须从保护模式切换到实模式；

x86 - 64所支持的模式及这些模式的特点：

 ![1578643018(1)](resources\1578643018(1).jpg)

### x86 - 64 的寄存器组

x86架构的寄存器可以分为：

- 通用寄存器：用来保存程序运行时的临时变量栈指针等数据；
- 内存管理寄存器：包括段寄存器和描述表寄存器；
- 标志寄存器：用来保存程序运行中的一些标志位信息，如溢出、开启中断与否、分支跳转等信息；
- 指令寄存器：用来保存指向当前指令的地址，又称PC指针；
- 控制寄存器：x86提供5个寄存器：CR0 ~ CR4，这些寄存器决定CPU运行的模式和特征。64位模式引入CR8，它被定义为任务优先级寄存器（TPR），操作系统能够基于中断的优先级别来使用TPR来控制是否允许外部中断来中断处理器。
- 其他寄存器：包括调试寄存器(DR)，内存区域类型寄存器(MTRR)，机器检查寄存器以及性能监控寄存器；

 ![1578643340(1)](resources\1578643340(1).jpg)

### 中断与异常

**1.中断架构**

​	中断机制使外部硬件可以打断CPU当前的执行任务，使CPU为自己提供服务。中断从设备经由"中断控制器"转发给CPU(MSI除外)。中断控制器经历了PIC和APIC两个阶段。

​	PIC具有IR0 ~ IR7共8个中断管脚可以与外部设备相连，其中IR0优先级最高，IR7优先级最低。此外，PIC还有一个EOI位，当CPU处理完一个中断时，通过写EOI位告知PIC中断处理完成。

​	LAPIC也有IRR、ISR和EOI寄存器，其中IRR和ISR为256位，EOI为32位，它们的功能和PIC中的相应设备基本相同。

**2.异常架构**

​	中断由外部设备产生，异常由CPU内部产生，其原因是CPU当前执行的指令出了问题。

​	异常分为三类：

- 错误(Fault)：有某种错误情况引起，一般可以被错误处理程序纠正。
- 陷阱(Trap)：指在执行一条特殊指令后引起的异常。陷阱最重要的用途是在用户程序和内核之间一个像过程一样的接口(系统调用)。Linux用于实现系统调用的INT 80指令。
- 终止(Abort)：指严重的不可恢复的错误，将导致程序终止。典型的是一些硬件错误。

**3.中断门和异常门**

​	IDT表是一个大数组，用于存放各种"门"。是中断和异常通往各自处理函数的入口。当一个中断或异常发生时，CPU用它们对应的vector号索引IDT表以获得对应的门。

​	中断门是一种段描述符，称为系统描述符，有段描述符的S位控制，中断门格式：

 ![1578658042(1)](resources\1578658042(1).jpg)

其中，段选择符、偏移量字段可以看成一个逻辑地址，通过索引GDT将该逻辑地址转换成中断处理函数入口的线性地址。

陷阱门和中断门类似，格式如下：

 ![1578658145(1)](resources\1578658145(1).jpg)

中断门和陷阱门的唯一区别是程序通过中断门跳转后，EFLAGS寄存器的IF位自动清零，中断关闭。而陷阱门没有这样的效果。

**4.中断和异常总结**

 ![1578658225(1)](resources\1578658225(1).jpg)

### I/O 架构

计算机所处理的任务只有两种：CPU运算和I/O操作。CPU通过读/写寄存器和RAM完成对设备的访问以及其他操作。

按照访问方式不同，x86架构的I/O分为两类：

1. 端口I/O：通过I/O端口访问设备寄存器。CPU将端口号作为设备端口的地址，进而对设备进行访问。I/O端口地址空间是独立的，不是线性地址空间或物理地址空间的一部分。需要使用特定的操作命令IN/OUT对端口进行访问。
2. 内存映射I/O：通过内存访问的形式访问设备寄存器或设备RAM。MMIO要占用CPU的物理地址空间，将设备寄存器或设备RAM映射到物理地址空间的某段地址，然后使用MOV等访存指令访问此段地址，即可访问到映射的设备。

### DMA

​	直接内存访问(DMA)允许设备绕开CPU直接向内存中复制或读取数据。如果设备向内存复制数据都经过CPU，则CPU会有大量中断负载，中断过程中，CPU对其他任务无法使用，不利于系统性能的提高。

​	通过DMA，CPU只负责初始化这个传输动作，而传输动作本身由DMA控制器来完成。一个完整的DMA传输过程基本流程如下：

1. DMA请求：CPU对DMAC进行初始化，并向I/O端口发出操作命令，I/O端口提出DMA请求；
2. DMA响应：DMAC对DMA请求进行优先级判别和屏蔽判别，然后向总线裁决逻辑提出总线请求。CPU执行完当前总线周期后释放总线控制权。此时，总线裁决逻辑发出总线应答，表示DMA已被响应，并通过DMAC通知I/O端口开始DMA传输；
3. DMA传输：DMAC获得总线控制权后，CPU即可挂起或只执行内部操作，由DMAC发出读/写命令，直接控制RAM与I/O端口进行DMA传输；
4. DMA结束：当完成规定的成批数据传送后，DMAC释放总线控制权，并向I/O端口发出结束信号。当I/O端口收到结束信号，停止I/O设备的工作并向CPU提出中断请求，是CPU执行一段检查本次DMA传输操作正确性的判断；

 ![1578659057(1)](resources\1578659057(1).jpg)

### 时钟

​	操作系统的很多事件都是由时钟驱动的，如进程调度、定时器等。根据时钟工作方式不同，可以分为两类：

- 周期性时钟：时钟以固定频率产生时钟中断。通常会有一个计数器，要么以固定值递减到0产生中断，如PIT；要么固定增长，当达到某个阈值时产生中断，同时自动将阈值增加一个固定值，计数器继续递增，如HPET；
- 单次计时时钟：工作方式和达到阈值产生中断的周期性时钟类似，只是产生中断后阈值不会自动增加，而是需要时钟中断处理函数等软件来增加该阈值。这为软件提供动态调整下一次时钟中断到来时间的能力。

## 操作系统和虚拟化

### 操作系统

​	操作系统最核心的功能是管理进程调度、管理内存的分配使用以及管理各种设备，负责这些工作的程序叫内核(Kernel)。内核运行在CPU最高的特权级上，应用程序运行在CPU最低的特权级上，只能访问部分资源。

### 进程

一个进程包含的资源：

1. 私有的线性地址空间：这是进程能够使用的线性地址总和，其中内核部分可能是和其他进程共享的。
2. 可执行的程序：代码和数据的二进制序列。
3. 一些已经获得的其他资源，如打开的文件、管道等。
4. 进程的权限：即进程的运行权限，例如，在Linux中就有root用户和非root用户。
5. 进程描述符：有些操作系统称为控制块，包含操作该进程的一些必要的信息，例如进程ID。

和虚拟技术相关的上下文

**上下文**

​	上下文是从CPU的角度引出的。是程序(进程或中断)运行时所需要的最小寄存器集合。这些寄存器的一般代表程序运行的一类资源，例如，LDTR代表某个进程所使用的段信息，CR3寄存器代表进程的私有线性地址空间。

x86架构上下文包含的寄存器列举：

- 通用寄存器组：EAX、EBX、ECX、EDX、ESI、EDI，以及ESP(栈指针)和EBP(框架指针)；
- 段相关寄存器组：CS、DS、SS，如果程序使用ES、FS、GS等额外段寄存器，也包含进来；
- 标志寄存器：EFLAGS；
- 程序指针寄存器：EIP；
- GDT基地址：GDTR中的内容，用于访问GDT；
- LDT段选择符：程序使用私有的LDT时LDTR中的内容；
- IDT基地址：IDTR中的内容，用于访问IDT；
- 控制寄存器组：CR系列，表示当前程序运行时的CPU控制状态；
- 浮点相关寄存器组：用于浮点计算的一些寄存器组；
- 特使用途的寄存器：x86架构下的MSR；

**上下文切换**

​	上下文切换是从用户态切换到内核态，或进程切换，导致上下文相关寄存器值的变换。

在操作系统中会发生上下文切换的场合举例：

- 用户态和内核态的切换：进程的用户态和内核态运行在不同的Ring级别，对资源的访问权限不同，因而在用户态和内核态相互切换的时候需要切换部分上下文；
- 进程切换：一个CPU在一个时刻只能处理一个进程，进程切换的实质就是将被终止运行的进程的上下文相关寄存器的值换成新进程的相关值，同时将被终止运行的进程的上下文相关寄存器的值存储在该进程的私有堆栈中；
- 切换到中断上下文：中断的处理函数运行在中断上下文环境中。CPU在处理一个中断时，需要由当前环境切换到该中断的上下文。需要对栈指针、EIP的值等进行更改，而CR3的值则不需要更改；

上下文切换通常有两个步骤：

1. 保存旧上下文：将被终止进行的程序或被切换出来的状态(如被内核态切换出去的用户态)的上下文相关寄存器的值保存到内存中(如进程的私有堆栈)。
2. 加载新上下文：将切换到的程序(如新程序)或新状态(如切换到的内核态)运行需要的上下文相关寄存器的值从内存中读入并加载到对应的寄存器中。


### 系统虚拟化

​	系统虚拟化是将一台物理计算机系统虚拟化为一台或多台虚拟计算机系统，每个虚拟计算机系统拥有自己的虚拟硬件(包括CPU、内核、设备等)，以便提供一个独立的虚拟机执行环境。

​	虚拟化层就是VMM，通过虚拟化层模拟，虚拟机中的操作系统认为自己仍然独占一个系统在运行。

 ![1578819733(1)](resources\1578819733(1).jpg)

一台虚拟机需要具有三个典型特诊

- 同质：虚拟机的运行环境和物理机的环境在本质上是相同的，但是表现上有一些差异；
- 高效：虚拟机中运行的软件需要有接近在物理机上直接运行的性能；
- 资源受控：VMM需要对系统资源有完全控制能力和管理权限，包括资源分配、监控和回收；

**特权指令**：只能运行在最高特权级上正确运行，如果在非最高特权级上运行，则会引发异常使用处理器陷入到最高特权级，进而将特权指令由系统软件处理。

**敏感指令**：虚拟化技术的概念，指操作特权资源的指令。包括修改虚拟机的运行模式或物理机的状态：读/写敏感的寄存器或内存；访问存储保护系统，内存系统或是地址重定位系统以及所有的I/O指令。

## VMM技术架构分类

当前主流的VMM技术架构分为三类：Hypervisor模型，宿主(Hosted)模型和混合模型。

### Hypervisor模型

​	在Hypervisor模型中，可以将VMM看做是一个完备的操作系统，但VMM还具备虚拟化功能。VMM承担管理物理资源(处理器、内存和I/O设备)责任。

 ![1578820770(1)](resources\1578820770(1).jpg)

- P(Process)负责物理处理器的管理和虚拟化
- M(Memory)负责物理内存的管理和虚拟化
- DM(Device Model)负责I/O设备的虚拟化
- DR(Device Driver)负责I/O设备的驱动

### 宿主(Hosted)模式

​	VMM负责提供传统操作系统所不具备的虚拟化功能。VMM通常是宿主机操作系统独立的内核模块，有些还包括用户态进程(负责I/O虚拟化的用户态设备模型)。VMM通过调用宿主机操作系统的服务来获得资源，实现处理器、内存和I/O设备的虚拟化。VMM将其创建出的虚拟机作为宿主机操作系统的一个进程参与调度。

 ![1578821104(1)](resources\1578821104(1).jpg)

​	宿主模型最大的优点是可以充分利用现有操作系统的的设备驱动程序，VMM无须为I/O设备实现驱动程序，只需专注于物理资源的虚拟化。此外，宿主模型还可以直接使用宿主机操作系统的其他功能。

### 混合模型

​	混合模型是上述两种模型的综合。VMM位于最底层，拥有所有的物理资源。但是VMM将大部分I/O设备的控制权交由一个运行在特权虚拟机中的特权操作系统来控制。

​	同时VMM的虚拟化职责也被特权操作系统所分担，处理器和内存的虚拟化由VMM完成，而I/O的虚拟化则由VMM和特权操作系统共同完成。

 ![1578821859(1)](resources\1578821859(1).jpg)

​	在混合模型中，VMM可以利用现有操作系统的I/O设备驱动程序，也可以直接控制处理器、内存等物理资源。

## 虚拟化实现架构

​	VMM对物理资源的虚拟可以归结为三个主要任务：处理器虚拟化、内存虚拟化和I/O虚拟化。

​	Intel VT是Intel平台上硬件虚拟化技术的总称，包含对CPU、内存和I/O设备等各个方面的虚拟化支持。

 ![1578823424(1)](resources\1578823424(1).jpg)

VMM典型结构分为两层：上层是通用功能，如资源管理，系统调度等；下层是平台相关，即使用Intel VT实现的处理器虚拟化、内存虚拟化和I/O虚拟化。

- 在处理器虚拟化方面，提供VT-x技术
- 在内存虚拟化方面，提供EPT技术
- 在I/O设备虚拟化方面，提供VT-d技术

AMD平台也提供类似的技术，AMD SVM提供处理器虚拟化技术；内存方面 AMD SVM 提供NPT技术；I/O设备虚拟化方面，提供IOMMU技术

### 处理器虚拟化

​	VMM陷入是通过处理器的保护机制，利用中断和异常来完成的。VMM陷入方式有几种：

1. 基于处理器保护机制触发的异常。处理器在执行敏感命令之前，检查其执行条件是否满足(包括当前特权级别、运行模式、内存映射关系等)，一旦任一条件不满足，就会陷入VMM进行处理。
2. 虚拟机主动触发异常，也就是陷阱。
3. 异步中断，包括处理器内部的中断源和外部的设备中断源。可以是周期性产生中断的时钟源，也可以是根据设备状态产生中断的大多数外设。

**Intel VT**

VT-x引入两种操作模式：根操作模式和非根操作模式，它们统称为VMX操作模式。

1. 根操作模式：VMM运行时所处的模式，在根模式下，所有指令的行为和传统的IA32一样，因此，原来的软件都可以正常运行。
2. 非根操作模式：客户机运行时所处的模式，所有敏感指令的行为都被重新定义，使得它们能不经过虚拟化就直接运行或者通过"陷入再模拟"的方式来处理。

 ![1578824065(1)](resources\1578824065(1).jpg)

​	根模式和非根模式都有相应的特权级0 ~ 特权级3。所以，在使用VT-x时，描述程序运行在某一个特权级时，必须指明当前是处于何种模式。

​	VT-x中，在非根模式下，敏感指令引起的陷入称为VM-Exit。VM-Exit发生时，CPU自动从非根模式切换到根模式。与VM-Exit相对应的是VM-Entry，该操作由VMM发起。通常是VMM调度某个客户机运行时CPU由根模式切换成非根模式。

​	VT-x还引入VMCS(虚拟机控制结构)，以便更好支持CPU虚拟化。VMCS保存虚拟CPU需要的相关状态。

**AMD SVM**

​	AMD SVM在处理器上提供硬件资源，允许单个机器高效运行多个操作系统，并维护安全和资源相互隔离。AMD SVM也引入根模式和非根模式两种操作模式。并引入VMCB(虚拟机控制块)，支持CPU虚拟化。

**vCPU**

​	硬件虚拟化使用vCPU描述符来描述虚拟CPU。vCPU描述符类似操作系统的进程描述符，本质是一个结构体，组成部分如下：

- vCPU标识信息：用于标识vCPU的一些属性，如ID号，vCPU属于哪个客户机等；
- 虚拟寄存器信息：虚拟的寄存器资源，这些内容包含在VMCS/VMCB中，包含客户机状态域保存的内容；
- vCPU状态信息：类似进程的状态信息，标识该vCPU当前所处的状态(睡眠、运行等)，主要供调度器使用；
- 额外寄存器/部件信息：指未包含在VMCS/VMCB中的一些寄存器或CPU部件。例如浮点寄存器和虚拟的LAPCI；
- 其他信息：用于VMM进行优化或额外存储信息的字段，例如，存放该vCPU私有数据的指针；

### 中断虚拟化

​	物理平台的中断架构：首先，I/O设备通过中断控制器(I/O APIC 或者 PIC)发送中断请求，中断请求经由PCI总线发送到系统总线上，最后目标CPU的Local APIC部件接收中断，目标CPU再对该中断进行处理。

​	在虚拟环境中，展现一个与物理中断架构类似的虚拟中断架构;

 ![1578825136(1)](resources\1578825136(1).jpg)

​	每一个vCPU都对应一个虚拟Local APIC用于接收中断。虚拟平台包含虚拟I/O APIC或者虚拟PIC用于发送中断。虚拟Local APIC、虚拟I/O APIC和虚拟PIC都是由VMM维护的软件实体。

​	当虚拟设备需要发送中断时，虚拟设备会调用虚拟I/O APIC的接口发送中断；而虚拟I/O APIC根据中断请求，挑选相应的虚拟Local APIC，并调用其接口发出中断请求。虚拟Local APIC进一步利用Intel VT-x的事件注入机制将中断注入到相应的vCPU。

### 内存虚拟化

​	一个操作系统对其物理内存存在两个主要的基本认识：物理地址从0开始和内存地址连续性。而VMM与客户机操作系统对物理内存的认识上存在冲突，这使得真正拥有物理内存的VMM必须对客户机操作系统所访问的内存进行一定程度的虚拟化。

​	内存虚拟化引入一个新的地址空间 - 客户机物理地址空间。

 ![J4R}7W(33ZVIG$30UX)7BF](resources\J4R}7[W(33ZVIG$30UX)7BF.png)

​	由于引入客户机物理地址空间，内存虚拟化需要通过两次地址转换来支持地址空间的虚拟化，即客户机虚拟地址(GVA) - > 客户机物理地址(GPA) - > 宿主机物理地址(HPA)的转换。其中：GVA - > GPA的转换是由客户机软件决定；GPA - > HPA的转换由VMM决定的。

**1. 影子页表**

​	传统的x86架构只支持一次地址转换，即通过CR3指定的页表实现从虚拟地址到物理地址的转换。这和内存虚拟化所要求的两次地址转换产生矛盾。通过"影子页表"的方式将两次转换合并为一次转换来解决这个问题。

​	一份影子页表与一份客户机操作系统的页表对应，将GVA直接映射到HPA。

 ![1579005016(1)](resources\1579005016(1).png)

**MMU的虚拟化**

​	如果MMU直接装载客户机操作系统维护的页表来进行内存访问，由于页表中所记录的都是GPA，硬件无法正确地通过多级页表来进行地质翻译。所以，VMM还需要对MMU实现虚拟化。

​	客户机操作系统所能看到和操作的都是虚拟MMU，客户机操作系统所维护的页表只是被客户机操作系统载入到虚拟机MMU中，不能被物理MMU直接使用。VMM在物理MMU中载入的是影子页表。

 ![1579005284(1)](resources\1579005284(1).jpg)

​	在影子页表的实现过程中，影子页表的页表结构并不一定与客户机页表的页表结构完全一致。比如64位机上模拟32位机，只要保证相对同一个虚拟地址，在影子页表中最后那级页表的页表项，所指向的宿主机物理页是且必须是客户机物理页在客户机物理地址与宿主机物理地址映射表中相对应的宿主机物理页。

**影子页表建立与维护**

​	主要包括三种：VMM对客户机操作系统修改客户机CR3寄存器的截获与处理、VMM对客户机操作系统INVLPG指令的截获与处理，VMM对因客户机页表和影子页表不一致而触发的缺页异常的截获与处理。

1. 缺页异常分类

   - 影子页表初始化时的缺页异常：开始时，VMM中与客户机操作系统拥有的页表相对应的影子页表是空的，但是影子页表又是载入到物理CR3中为物理MMU所利用进行寻址的页表，因此，开始时任何的内存访问操作都会引起缺页异常。处理这种异常的过程就完成影子页表初始化的过程。
   - VMM将宿主机物理页换出到硬盘上引发的缺页异常：这种情况，虽然客户机操作系统为所访问的客户机虚拟地址分配客户机物理页，但是由于VMM没在影子页表中为这个客户机虚拟地址建立相应的到宿主机物理地址的映射，便引发缺页异常。
   - 客户机上的缺页异常：如果客户机操作系统尚未给这个客户机虚拟地址分配客户机物理页，即相应的客户机操作系统页表中没有这个客户机虚拟地址到某一客户页的映射，这时也会引发缺页异常。此外，客户机锁访问的客户页表项存在位为0，或者写一个只读的客户机物理页，也会引发缺页异常。

2. 影子页表的缺页处理机制

   ​	VMM首先截获到缺页异常的发生，并将发生异常的客户机虚拟地址在客户机页表中对应页表项的访问权限位于缺页异常的错误码进行比较，从而检查此缺页异常是否由客户机本身引起。

   ​	若由客户机本身引起的缺页异常，VMM直接返回给客户机操作系统，再由客户机操作系统的缺页异常处理机制来处理该缺页异常；若缺页异常不是由客户机引起，那么必定是由客户机页表和影子页表不一致。对于**影子缺页异常**，VMM会根据客户机页表同步影子页表。同步过程如下

   - VMM根据客户机页表项建立相应的影子页目录和页表结构：VMM在为它建立影子页表时，会根据GFN找到与之对应的映射在宿主机上的物理页帧号(MFN)。客户机认为存储在该GFN中的数据实际上是存储在MFN中的；
   - VMM根据发生缺页异常的客户机虚拟地址，在客户机页表的相应页表项中得到与之对应的客户机物理地址；
   - 根据客户机物理地址，在客户机物理地址与宿主机物理地址映射中得到相应的宿主机物理地址，VMM再把这个宿主机物理地址填入影子页表项中；VMM还根据客户页表项的访问位和修改位设置对应影子页表项的访问位和修改位；

3. 影子页表总结

   ​	影子页表和客户机页表不是时刻同步的，只有在需要的时候才进行同步。影子页表可以看做是客户机页表巨大的TLB，称为TLB。当客户机操作系统需要访问它的客户机页表时，物理MMU真正访问的是被称为"虚拟TLB"的影子页表。

   ​	当客户机页表被修改时，若影子页表中对应客户机页表的表项访问权限低于客户机页表表项的，VMM会截获一个缺页异常，这可以理解为TLB未命中，它表示尽管客户机页表中锁访问的是合法的地址映射，但是影子页表中尚未建立起与之对应的映射，即发生影子缺页异常。此时，VMM根据客户机页表的客户机虚拟地址到客户机物理地址的映射，在影子页表中建立相应的客户机虚拟地址到宿主机物理地址的映射，并置相应的权限位，相当于TLB填充。

   ​	当客户机修改客户机页表的表项时，由于客户机执行敏感指令重写CR3或执行INVLPG敏感指令刷新TLB，VMM将截获这一操作，并对影子页表进行相应的修改，刷新影子页表中的全部或部分内容，就相当于TLB刷新。

**影子页表的缺点**

影子页表解决传统IA32架构的内存虚拟化问题，但它的缺点比较明显，具体如下。

- 首先，实现非常复杂，需要考虑各种各样的页表同步情况。
- 其次，影子页表的内存开销很大，需要为每个客户机进程对应的页表都维护一个"影子页表"。

**2. Intel EPT**

​	Intel EPT(Extended Page Table)基本原理如图，在原本的CR3页表地址映射的基础上，EPT引入EPT页表来实现另一次映射。这里假设客户机页表和EPT页表都是4级页表，CPU完成一次地址转换的基本过程如下：

 ![1579007907(1)](resources\1579007907(1).jpg)

1. CPU首先查找客户机CR3寄存器指向的L4页表。客户机CR3寄存器给出的是GPA，所以，CPU通过EPT页表将客户机CR3中的GPA转换为HPA：CPU查找EPT TLB，如果没有相应的记录，就进一步查找EPT页表，如果还没有，CPU则抛出EPT Violation异常交给VMM处理。
2. 获取L4页表地址后，CPU根据GVA和L4页表项的内容来获取L3页表项的GPA。如果L4页表中GVA对应的表项显示为"缺页"，那么CPU产生Page Fault，直接交由客户机操作系统处理。获得L3页表项的GPA后，CPU通过查询EPT页表来将L3的GPA转换为HPA。
3. 同理，CPU会依次完成L2、L1页表的查询，获得GVA所对应的GPA，然后进行最后一次查询EPT页表获得HPA。

CPU需要5次查询EPT页表，每次查询都需要4次内存访问。这样，在最坏的情况总共需要20次内存访问。EPT硬件通过增大EPT TLB来尽量减少内存访问。

**3. AMD NPT**

​	AMD NPT(Nested Page Table)是AMD提供的内存虚拟化支持技术。

​	如图，传统的分页技术下的地址转换是直接将线性地址空间上的线性地址转换为物理地址空间上的物理地址。CR3寄存器中存储着页表的物理基地址。

 ![1579008771(1)](resources\1579008771(1).jpg)

嵌套分页技术的原理如图：

 ![1579008818(1)](resources\1579008818(1).jpg)

1. 客户机和宿主机都有自己的CR3寄存器，分别记为gCR3(guest CR3)和nCR3(nested CR3)。真正的CR3由VMM所控制和使用。
2. gPT负责将客户机线性地址转换为客户机物理地址。客户机页表存在于客户机物理内存中，并由gCR3索引。
3. nPT负责将客户机物理地址转换为系统物理地址。嵌套页表存在于系统物理内存中，并由nCR3索引。
4. 最常用的客户机线性地址到系统物理地址的映射关系在TLB中缓存。
5. gCR3和客户机页表中存放的都是客户机物理地址，所以，在访问客户机页表前需要将客户机物理地址转换为系统物理地址。

### I/O设备虚拟化

I/O设备虚拟化面临两个基本问题：

- 让客户机直接访问到设备真实的I/O地址空间(包括端口I/O和MMIO)；
- 让设备的DMA操作直接访问到客户机的内存空间。


**1. Intel VT-d**

​	在启用VT-d平台上，设备所有的DMA传输都会被DMA重映射硬件截获。根据设备对应的I/O页表，硬件可以对DMA中的地址进行转换，使设备只能访问到规定的内存。

使用VT-d，设备访问内存架构：

 ![1579067487(1)](resources\1579067487(1).jpg)

​	(a)是没有VT-d平台，此时设备的DMA可以访问整个物理内存，(b)是启用VT-d，此时设备只能访问指定的物理内存。这将使用页表将进程的线性地址空间映射到指定物理内存区域的思想一样，只不过对象换成了设备。

**2. DMA重映射**

​	设备对系统中运行的软件一无所知，在进行DMA时，设备唯一做的就是从驱动程序告知的物理地址复制数据。虚拟机环境下客户机使用的是GPA，客户机的驱动直接操作设备时也用GPA。但是，设备在DMA操作时，需要使用MPA，于是I/O虚拟化的关键问题就是如何操作DMA时将GPA转换成MPA。设备的DMA操作通常无法通过软件方法截获，VT-d技术提供DMA重映射来解决在DMA时将GPA转换为MPA的问题。

​	VT-d中PCI总线架构：设备标识符(BDF)、根条目(Root Entry)和上下文条目(Context Entry).

**BDF**

​	BDF可以看做是设备在PCI总线上的地址。通过BDF可以索引到任何一条总线上的任何一个设备。对于PCI总线，VT-d使用BDF作为源标识符，标识DMA操作的发起者。

 ![1579068015(1)](resources\1579068015(1).jpg)

- Bus：设备所在的总线号；
- Device：设备号；
- Function：功能号，标识具体设备上的某个功能单元，称为逻辑设备。

**根条目**

​	根条目用于描述PCI总线，每条总线对应一个根条目。这些根条目构成一张表，在表中，系统的每一条总线都会被描述到。

 ![1579068181(1)](resources\1579068181(1).jpg)

- P：存在位。为0时，条目无效，来自该条目所代表总线的所有DMA传输被屏蔽；为1时，条目有效；
- CTP：指向上下文条目表；

**上下文条目**

​	用于描述某个具体的PCI设备。公有256个上下文条目。这些一起构成一张表，称为上下文条目表。在表中，某条PCI总线上的所有设备都能被描述到。

 ![1579068340(1)](resources\1579068340(1).jpg)

- P：存在位。为0时，条目无效；为1时，条目有效；
- T：类型，表示ASR字段所指数据结构的类型；该字段设为0，表示多级页表；
- ASR(地址空间根)：一个指针，指向T字段所表示的数据结构，目前该字段指向一个I/O页表；
- DID：用于唯一标识某客户机的标识符；

根条目表和上下文条目表共同构成的两级结构：

 ![1579068552(1)](resources\1579068552(1).jpg)

​	当DMA重映射硬件捕获一个DMA传输时，通过其中BDF的Bus字段索引根条目表，可以得到产生此DMA传输的总线对应的根条目。由根条目的CTP字段可以获得上下文条目表，用BDF中{Dev:Function}索引该表，可以得到产生此DMA传输的设备对应的上下文条目。由上下文条目的ASR字段，可以寻址到该设备对应的I/O页表，此时，DMA重映射硬件就可以做地址转换了。

**3. I/O页表**

​	I/O页表是DMA重映射硬件进行地址转换的核心。I/O页表的核心思想与CPU中分页机制的页表类似。典型的4KB

页表地址转换过程

 ![1579069250(1)](resources\1579069250(1).jpg)

​	通过I/O页表中GPA到MPA的映射，DMA重映射硬件将DMA传输中的GPA转换成MPA，从而使设备能够直接访问指定客户机的内存区域。

**4. AMD IOMMU**

​	它位于外围设备和主机之间，可以把DMA I/O总线和PC系统主内存连接在一起，将虚拟内存地址映射为物理内存地址，并检查每个接入的适当权限。
















